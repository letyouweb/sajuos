"""
GPT í•´ì„ ì—”ì§„
- OpenAI APIë¥¼ í†µí•œ ì‚¬ì£¼ í•´ì„
- í† í° ë¹„ìš© í†µì œ
- êµ¬ì¡°í™”ëœ JSON ì‘ë‹µ
"""
import json
import logging
from typing import Optional, Dict, Any
from openai import AsyncOpenAI

from app.config import get_settings
from app.models.schemas import (
    ConcernType, 
    InterpretResponse,
    CalculateResponse
)
from app.rules.interpretation_rules import (
    get_full_system_prompt,
    get_lucky_elements
)

logger = logging.getLogger(__name__)


class GptInterpreter:
    """
    GPT ê¸°ë°˜ ì‚¬ì£¼ í•´ì„ ì—”ì§„
    """
    
    def __init__(self):
        self.settings = get_settings()
        
        # API í‚¤ ê²€ì¦
        if not self.settings.openai_api_key:
            logger.error("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        else:
            # í‚¤ ì¼ë¶€ë§Œ ë¡œê¹… (ë³´ì•ˆ)
            key_preview = self.settings.openai_api_key[:8] + "..." if len(self.settings.openai_api_key) > 8 else "???"
            logger.info(f"âœ… OpenAI API Key loaded: {key_preview}")
        
        self.client = AsyncOpenAI(api_key=self.settings.openai_api_key)
        self.model = self.settings.openai_model
        self.max_output_tokens = self.settings.max_output_tokens
    
    async def interpret(
        self,
        saju_data: Dict[str, Any],
        name: str,
        gender: Optional[str],
        concern_type: ConcernType,
        question: str
    ) -> InterpretResponse:
        """
        ì‚¬ì£¼ í•´ì„ ì‹¤í–‰
        """
        
        # API í‚¤ ê²€ì¦
        if not self.settings.openai_api_key:
            logger.error("âŒ OPENAI_API_KEYê°€ ë¹„ì–´ìˆìŒ - fallback ë°˜í™˜")
            return self._create_fallback_response(name, "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = get_full_system_prompt(concern_type)
        
        # 2. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = self._build_user_prompt(
            saju_data, name, gender, concern_type, question
        )
        
        # 3. GPT API í˜¸ì¶œ
        try:
            logger.info(f"ğŸš€ GPT í˜¸ì¶œ ì‹œì‘: model={self.model}, name={name}")
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=self.max_output_tokens,
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            logger.info(f"âœ… GPT ì‘ë‹µ ì„±ê³µ")
            
            # 4. ì‘ë‹µ íŒŒì‹±
            content = response.choices[0].message.content
            tokens_used = response.usage.total_tokens if response.usage else None
            
            result = self._parse_response(content, name)
            result["model_used"] = self.model
            result["tokens_used"] = tokens_used
            
            return InterpretResponse(**result)
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._create_fallback_response(name, f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ GPT API ì˜¤ë¥˜: {error_msg}")
            
            # ìƒì„¸ ì—ëŸ¬ ë¶„ë¥˜
            if "api_key" in error_msg.lower() or "authentication" in error_msg.lower():
                logger.error("ğŸ’¡ API í‚¤ ì¸ì¦ ì‹¤íŒ¨ - Railway í™˜ê²½ë³€ìˆ˜ í™•ì¸ í•„ìš”")
            elif "rate_limit" in error_msg.lower():
                logger.error("ğŸ’¡ Rate limit ì´ˆê³¼")
            elif "timeout" in error_msg.lower():
                logger.error("ğŸ’¡ íƒ€ì„ì•„ì›ƒ ë°œìƒ")
            
            return self._create_fallback_response(name, error_msg)
    
    def _build_user_prompt(
        self,
        saju_data: Dict[str, Any],
        name: str,
        gender: Optional[str],
        concern_type: ConcernType,
        question: str
    ) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        year_pillar = saju_data.get("year_pillar", saju_data.get("year", ""))
        month_pillar = saju_data.get("month_pillar", saju_data.get("month", ""))
        day_pillar = saju_data.get("day_pillar", saju_data.get("day", ""))
        hour_pillar = saju_data.get("hour_pillar", saju_data.get("hour", "ì—†ìŒ"))
        
        if isinstance(year_pillar, dict):
            year_pillar = year_pillar.get("ganji", str(year_pillar))
        if isinstance(month_pillar, dict):
            month_pillar = month_pillar.get("ganji", str(month_pillar))
        if isinstance(day_pillar, dict):
            day_pillar = day_pillar.get("ganji", str(day_pillar))
        if isinstance(hour_pillar, dict):
            hour_pillar = hour_pillar.get("ganji", str(hour_pillar))
        
        day_master = saju_data.get("day_master", day_pillar[0] if day_pillar else "")
        day_master_element = saju_data.get("day_master_element", "")
        
        gender_text = {
            "male": "ë‚¨ì„±",
            "female": "ì—¬ì„±",
            "other": "ê¸°íƒ€"
        }.get(gender, "ë¯¸ì…ë ¥")
        
        concern_text = {
            ConcernType.LOVE: "ì—°ì• /ê²°í˜¼",
            ConcernType.WEALTH: "ì¬ë¬¼/ê¸ˆì „",
            ConcernType.CAREER: "ì§ì¥/ì‚¬ì—…",
            ConcernType.HEALTH: "ê±´ê°•",
            ConcernType.STUDY: "í•™ì—…/ì‹œí—˜",
            ConcernType.GENERAL: "ì¢…í•©ìš´ì„¸"
        }.get(concern_type, "ì¢…í•©ìš´ì„¸")
        
        return f"""[ì‚¬ìš©ì ì •ë³´]
- ì´ë¦„: {name}
- ì„±ë³„: {gender_text}
- ê³ ë¯¼ ë¶„ì•¼: {concern_text}
- ì§ˆë¬¸: {question}

[ì‚¬ì£¼ ì›êµ­]
- ë…„ì£¼: {year_pillar}
- ì›”ì£¼: {month_pillar}
- ì¼ì£¼: {day_pillar}
- ì‹œì£¼: {hour_pillar if hour_pillar else "ë¯¸ì…ë ¥"}

[ì¼ê°„ ì •ë³´]
- ì¼ê°„(ë‚˜): {day_master}
- ì¼ê°„ ì˜¤í–‰: {day_master_element}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ê³ ë¯¼ì— ë§ëŠ” ì‚¬ì£¼ í’€ì´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
    
    def _parse_response(self, content: str, name: str) -> Dict[str, Any]:
        """GPT ì‘ë‹µ íŒŒì‹±"""
        try:
            data = json.loads(content)
            
            return {
                "success": True,
                "summary": data.get("summary", "ì‚¬ì£¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."),
                "day_master_analysis": data.get("day_master_analysis", ""),
                "strengths": data.get("strengths", ["ë¶„ì„ ì¤‘"]),
                "risks": data.get("risks", ["ë¶„ì„ ì¤‘"]),
                "answer": data.get("answer", ""),
                "action_plan": data.get("action_plan", ["ìì„¸í•œ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤."]),
                "lucky_periods": data.get("lucky_periods", []),
                "caution_periods": data.get("caution_periods", []),
                "lucky_elements": data.get("lucky_elements"),
                "blessing": data.get("blessing", f"{name}ë‹˜ì˜ ì•ë‚ ì— í–‰ìš´ì´ ê°€ë“í•˜ê¸¸ ë°”ëë‹ˆë‹¤. ğŸŒ¸"),
                "disclaimer": "ë³¸ í•´ì„ì€ ì˜¤ë½/ì°¸ê³  ëª©ì ìœ¼ë¡œ ì œê³µë˜ë©°, ì˜í•™/ë²•ë¥ /íˆ¬ì ë“± ì „ë¬¸ì  ì¡°ì–¸ì„ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }
        except json.JSONDecodeError:
            return {
                "success": True,
                "summary": "ì‚¬ì£¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "day_master_analysis": content[:500] if content else "",
                "strengths": ["ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."],
                "risks": ["ì£¼ì˜ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”."],
                "answer": content[:1000] if content else "",
                "action_plan": ["êµ¬ì²´ì ì¸ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤."],
                "lucky_periods": [],
                "caution_periods": [],
                "lucky_elements": None,
                "blessing": f"{name}ë‹˜ì˜ ì•ë‚ ì— í–‰ìš´ì´ ê°€ë“í•˜ê¸¸ ë°”ëë‹ˆë‹¤. ğŸŒ¸",
                "disclaimer": "ë³¸ í•´ì„ì€ ì˜¤ë½/ì°¸ê³  ëª©ì ìœ¼ë¡œ ì œê³µë˜ë©°, ì˜í•™/ë²•ë¥ /íˆ¬ì ë“± ì „ë¬¸ì  ì¡°ì–¸ì„ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }
    
    def _create_fallback_response(self, name: str, error_detail: str = "") -> InterpretResponse:
        """ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ (ì—ëŸ¬ ì›ì¸ í¬í•¨)"""
        logger.warning(f"âš ï¸ Fallback ì‘ë‹µ ìƒì„±: {error_detail}")
        
        return InterpretResponse(
            success=False,
            summary="ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            day_master_analysis="ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            strengths=["ì„œë¹„ìŠ¤ ë³µêµ¬ ì¤‘ì…ë‹ˆë‹¤."],
            risks=["ì¼ì‹œì  ì˜¤ë¥˜"],
            answer=f"í•´ì„ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            action_plan=["ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."],
            lucky_periods=[],
            caution_periods=[],
            lucky_elements=None,
            blessing=f"{name}ë‹˜, ê³§ ì •ìƒí™”ë©ë‹ˆë‹¤. ì–‘í•´ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
            disclaimer="ë³¸ í•´ì„ì€ ì˜¤ë½/ì°¸ê³  ëª©ì ìœ¼ë¡œ ì œê³µë˜ë©°, ì˜í•™/ë²•ë¥ /íˆ¬ì ë“± ì „ë¬¸ì  ì¡°ì–¸ì„ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            model_used="fallback",
            tokens_used=0
        )
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> dict:
        """ë¹„ìš© ì¶”ì •"""
        input_cost_usd = (input_tokens / 1_000_000) * 0.15
        output_cost_usd = (output_tokens / 1_000_000) * 0.60
        total_usd = input_cost_usd + output_cost_usd
        total_krw = total_usd * 1400
        
        return {
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "cost_usd": round(total_usd, 6),
            "cost_krw": round(total_krw, 2),
            "note": "GPT-4o-mini ê¸°ì¤€"
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
gpt_interpreter = GptInterpreter()

"""
Reports API Router v9 - ì§‘ê³„(Aggregation) ì‘ë‹µ + full_markdown
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
P0 í•µì‹¬ ìˆ˜ì •:
1) /view/{job_id} â†’ job + sections + full_markdown ì§‘ê³„ ë°˜í™˜
2) sections ìˆœì„œ ê°•ì œ: exec/money/business/team/health/calendar/sprint
3) ê° sectionì— markdown í•„ë“œ í¬í•¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
from fastapi import APIRouter, HTTPException, Request, BackgroundTasks, Query
from fastapi.responses import JSONResponse
from pydantic import BaseModel, EmailStr
from typing import Optional, Dict, Any, List
import logging
import uuid

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/reports", tags=["reports"])


class ReportStartRequest(BaseModel):
    email: EmailStr
    name: str = "ê³ ê°"
    saju_result: Optional[Dict[str, Any]] = None
    year_pillar: Optional[str] = None
    month_pillar: Optional[str] = None
    day_pillar: Optional[str] = None
    hour_pillar: Optional[str] = None
    target_year: int = 2026
    question: str = ""
    concern_type: str = "career"
    survey_data: Optional[Dict[str, Any]] = None


def get_supabase():
    try:
        from app.services.supabase_service import supabase_service
        return supabase_service
    except Exception as e:
        logger.error(f"Supabase import ì‹¤íŒ¨: {e}")
        return None


# ğŸ”¥ ì„¹ì…˜ ìˆœì„œ ê°•ì œ
SECTION_ORDER = ["exec", "money", "business", "team", "health", "calendar", "sprint"]

SECTION_SPECS = [
    {"id": "exec", "title": "Executive Summary", "order": 1},
    {"id": "money", "title": "Money & Cashflow", "order": 2},
    {"id": "business", "title": "Business Strategy", "order": 3},
    {"id": "team", "title": "Team & Partner", "order": 4},
    {"id": "health", "title": "Health & Performance", "order": 5},
    {"id": "calendar", "title": "12-Month Calendar", "order": 6},
    {"id": "sprint", "title": "90-Day Sprint", "order": 7},
]


def get_section_title(section_id: str) -> str:
    """section_idë¡œ title ì¡°íšŒ"""
    for spec in SECTION_SPECS:
        if spec["id"] == section_id:
            return spec["title"]
    return section_id or "Unknown"


def extract_markdown_from_section(section: Dict) -> str:
    """ì„¹ì…˜ì—ì„œ markdown ì¶”ì¶œ (ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì‹œë„)"""
    # 1) ì§ì ‘ markdown í•„ë“œ
    if section.get("markdown"):
        return section["markdown"]
    
    # 2) content í•„ë“œ
    if section.get("content"):
        return section["content"]
    
    # 3) raw_jsonì—ì„œ ì¶”ì¶œ
    raw_json = section.get("raw_json") or {}
    
    # 3-1) body_markdown
    if raw_json.get("body_markdown"):
        return raw_json["body_markdown"]
    
    # 3-2) content
    if raw_json.get("content"):
        return raw_json["content"]
    
    # 3-3) JSON ì „ì²´ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
    if raw_json:
        return build_markdown_from_raw_json(section.get("section_id", ""), raw_json)
    
    return ""


def build_markdown_from_raw_json(section_id: str, raw_json: Dict) -> str:
    """raw_jsonì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    lines = []
    title = raw_json.get("title") or get_section_title(section_id)
    lines.append(f"## {title}\n")
    
    # body_markdownì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if raw_json.get("body_markdown"):
        lines.append(raw_json["body_markdown"])
        return "\n".join(lines)
    
    # diagnosis
    diagnosis = raw_json.get("diagnosis")
    if diagnosis:
        lines.append("### ì§„ë‹¨")
        if diagnosis.get("current_state"):
            lines.append(f"**í˜„ì¬ ìƒíƒœ**: {diagnosis['current_state']}")
        if diagnosis.get("key_issues"):
            lines.append("**í•µì‹¬ ì´ìŠˆ**:")
            for issue in diagnosis["key_issues"]:
                lines.append(f"- {issue}")
        lines.append("")
    
    # hypotheses
    hypotheses = raw_json.get("hypotheses") or []
    if hypotheses:
        lines.append("### ê°€ì„¤")
        for h in hypotheses:
            lines.append(f"- **{h.get('id', '')}**: {h.get('statement', '')} (ì‹ ë¢°ë„: {h.get('confidence', '')})")
        lines.append("")
    
    # strategy_options
    options = raw_json.get("strategy_options") or []
    if options:
        lines.append("### ì „ëµ ì˜µì…˜")
        for opt in options:
            lines.append(f"#### {opt.get('name', '')}")
            lines.append(opt.get('description', ''))
            if opt.get('pros'):
                lines.append("**ì¥ì **: " + ", ".join(opt['pros']))
            if opt.get('cons'):
                lines.append("**ë‹¨ì **: " + ", ".join(opt['cons']))
        lines.append("")
    
    # recommended_strategy
    rec = raw_json.get("recommended_strategy")
    if rec:
        lines.append("### ì¶”ì²œ ì „ëµ")
        lines.append(f"**ì„ íƒ**: {rec.get('selected_option', '')}")
        lines.append(f"**ê·¼ê±°**: {rec.get('rationale', '')}")
        if rec.get("execution_plan"):
            lines.append("**ì‹¤í–‰ ê³„íš**:")
            for plan in rec["execution_plan"]:
                lines.append(f"- Week {plan.get('week', '')}: {plan.get('focus', '')} - {', '.join(plan.get('actions', []))}")
        lines.append("")
    
    # kpis
    kpis = raw_json.get("kpis") or []
    if kpis:
        lines.append("### KPI")
        for kpi in kpis:
            lines.append(f"- **{kpi.get('metric', '')}**: ëª©í‘œ {kpi.get('target', '')} (í˜„ì¬: {kpi.get('current', '')})")
        lines.append("")
    
    # risks
    risks = raw_json.get("risks") or []
    if risks:
        lines.append("### ë¦¬ìŠ¤í¬")
        for risk in risks:
            lines.append(f"- **{risk.get('risk', '')}**: í™•ë¥  {risk.get('probability', '')}, ì˜í–¥ {risk.get('impact', '')}")
            lines.append(f"  ëŒ€ì‘: {risk.get('mitigation', '')}")
        lines.append("")
    
    # Calendar ì „ìš©
    if section_id == "calendar":
        if raw_json.get("annual_theme"):
            lines.append(f"### ì—°ê°„ í…Œë§ˆ\n{raw_json['annual_theme']}\n")
        monthly = raw_json.get("monthly_plans") or []
        if monthly:
            lines.append("### ì›”ë³„ ê³„íš")
            for m in monthly:
                lines.append(f"#### {m.get('month_name', m.get('month', ''))}ì›”")
                lines.append(f"- í…Œë§ˆ: {m.get('theme', '')}")
                lines.append(f"- ì—ë„ˆì§€: {m.get('energy_level', '')}")
                lines.append(f"- í•µì‹¬: {m.get('key_focus', '')}")
                if m.get('recommended_actions'):
                    lines.append(f"- ì•¡ì…˜: {', '.join(m['recommended_actions'])}")
            lines.append("")
    
    # Sprint ì „ìš©
    if section_id == "sprint":
        if raw_json.get("mission_statement"):
            lines.append(f"### ë¯¸ì…˜\n{raw_json['mission_statement']}\n")
        
        for phase_key in ["phase_1_offer", "phase_2_funnel", "phase_3_content", "phase_4_automation"]:
            phase = raw_json.get(phase_key)
            if phase:
                lines.append(f"### {phase.get('theme', phase_key)}")
                lines.append(f"- ê¸°ê°„: {phase.get('weeks', '')}")
                if phase.get('goals'):
                    lines.append(f"- ëª©í‘œ: {', '.join(phase['goals'])}")
                if phase.get('deliverables'):
                    lines.append(f"- ì‚°ì¶œë¬¼: {', '.join(phase['deliverables'])}")
                if phase.get('kpis'):
                    lines.append(f"- KPI: {', '.join(phase['kpis'])}")
                lines.append("")
        
        milestones = raw_json.get("milestones")
        if milestones:
            lines.append("### ë§ˆì¼ìŠ¤í†¤")
            for day_key in ["day_30", "day_60", "day_90"]:
                m = milestones.get(day_key)
                if m:
                    lines.append(f"- **{day_key.replace('_', ' ').title()}**: {m.get('goal', '')} (ëª©í‘œ ë§¤ì¶œ: {m.get('revenue_target', '')})")
            lines.append("")
    
    return "\n".join(lines)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ë””ë²„ê·¸ ì—”ë“œí¬ì¸íŠ¸ (DB ì§ì ‘ í™•ì¸ìš©)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/debug/{job_id}")
async def debug_job(job_id: str):
    """
    ğŸ”¥ ë””ë²„ê·¸ìš©: DBì—ì„œ ì§ì ‘ job + sections ì¡°íšŒ
    ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸: https://api.sajuos.com/api/v1/reports/debug/{job_id}
    """
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        return {"error": "Supabase ë¯¸ì—°ê²°"}
    
    # 1) Job ì¡°íšŒ
    job = await supabase.get_job(job_id)
    if not job:
        return {"error": f"Job not found: {job_id}"}
    
    # 2) Sections ì¡°íšŒ (raw)
    sections_raw = await supabase.get_sections(job_id)
    
    # 3) ê° ì„¹ì…˜ì˜ raw_json êµ¬ì¡° í™•ì¸
    sections_debug = []
    for s in sections_raw:
        raw_json = s.get("raw_json") or {}
        sections_debug.append({
            "section_id": s.get("section_id"),
            "status": s.get("status"),
            "has_raw_json": bool(raw_json),
            "raw_json_keys": list(raw_json.keys()) if raw_json else [],
            "has_body_markdown": bool(raw_json.get("body_markdown")),
            "body_markdown_length": len(raw_json.get("body_markdown", "")),
            "body_markdown_preview": (raw_json.get("body_markdown", ""))[:200] + "..." if raw_json.get("body_markdown") else None,
        })
    
    return {
        "job_id": job_id,
        "job_status": job.get("status"),
        "job_progress": job.get("progress"),
        "sections_count": len(sections_raw),
        "sections_debug": sections_debug,
        "has_result_json": bool(job.get("result_json")),
        "has_markdown": bool(job.get("markdown")),
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ê³ ì • ê²½ë¡œ ë¨¼ì € (/{job_id} ë³´ë‹¤ ìœ„ì—!)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.post("/start")
async def start_report(
    payload: ReportStartRequest,
    background_tasks: BackgroundTasks,
    request: Request
):
    """ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘"""
    # ğŸ”¥ P0: input_jsonì— saju_result í¬í•¨ (ì´ë©”ì¼ ë§í¬ì—ì„œë„ birth/time í‘œì‹œ ê°€ëŠ¥)
    input_data = {
        "name": payload.name,
        "question": payload.question,
        "concern_type": payload.concern_type,
        "target_year": payload.target_year,
        "survey_data": payload.survey_data,
        "saju_result": payload.saju_result,  # ğŸ”¥ í•µì‹¬: ì‚¬ì£¼ ê³„ì‚° ê²°ê³¼ ì €ì¥
        "year_pillar": payload.year_pillar,
        "month_pillar": payload.month_pillar,
        "day_pillar": payload.day_pillar,
        "hour_pillar": payload.hour_pillar,
    }
    
    supabase = get_supabase()
    
    if supabase and supabase.is_available():
        try:
            job = await supabase.create_job(
                email=payload.email,
                name=payload.name,
                input_data=input_data,
                target_year=payload.target_year
            )
            job_id = job["id"]
            public_token = job.get("public_token")
            
            logger.info(f"[Reports] Job ìƒì„± ì™„ë£Œ: {job_id}, token={public_token[:8] if public_token else 'NULL'}...")
            
            # ì„¹ì…˜ ì´ˆê¸°í™”
            try:
                await supabase.init_sections(job_id, SECTION_SPECS)
            except Exception as e:
                logger.warning(f"ì„¹ì…˜ ì´ˆê¸°í™” ìŠ¤í‚µ: {e}")
            
            # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
            rulestore = getattr(request.app.state, "rulestore", None)
            background_tasks.add_task(run_report_job, job_id, rulestore)
            
            # ğŸ”¥ P0: í‘œì¤€í™”ëœ ì‘ë‹µ (job_id, token, view_url)
            return {
                "success": True,
                "job_id": job_id,
                "token": public_token,
                "status": "queued",
                "message": "ë¦¬í¬íŠ¸ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "view_url": f"https://sajuos.com/report/{job_id}?token={public_token}",
                "status_url": f"https://api.sajuos.com/api/v1/reports/{job_id}/status",
                "result_url": f"https://api.sajuos.com/api/v1/reports/{job_id}/result",
            }
        except Exception as e:
            logger.error(f"Job ìƒì„± ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=str(e)[:300])
    else:
        temp_id = str(uuid.uuid4())
        return {
            "success": True,
            "job_id": temp_id,
            "status": "queued",
            "message": "ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (Supabase ë¯¸ì—°ê²°)",
        }


@router.get("/start")
async def start_report_get():
    """GET /startëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ"""
    return {"error": "Use POST method", "method": "POST /api/reports/start"}


@router.get("/sections-info")
async def get_sections_info():
    """ì„¹ì…˜ ì •ë³´"""
    return {"sections": SECTION_SPECS}


@router.get("/view/{job_id}")
async def view_report(job_id: str, token: str = Query(..., description="Access token")):
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ P0 í•µì‹¬: job + sections + full_markdown ì§‘ê³„ ë°˜í™˜
    í”„ë¡ íŠ¸ì—”ë“œ: /report/{job_id}?token=xxx â†’ ë°±ì—”ë“œ: /view/{job_id}?token=xxx
    """
    # UUID í˜•ì‹ ì²´í¬
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    # 1) token ê²€ì¦ (report_jobs.id + public_token)
    is_valid, job = await supabase.verify_job_token(job_id, token)
    
    if not is_valid or not job:
        raise HTTPException(status_code=404, detail="Invalid token or job not found")
    
    # 2) sections ì „ë¶€ ì¡°íšŒ
    sections_raw = await supabase.get_sections(job_id)
    
    # 3) ì„¹ì…˜ ìˆœì„œ ì •ë ¬: exec/money/business/team/health/calendar/sprint
    sections_sorted = sorted(
        sections_raw or [],
        key=lambda x: SECTION_ORDER.index(x.get("section_id", "")) if x.get("section_id") in SECTION_ORDER else 999
    )
    
    # 4) ê° ì„¹ì…˜ì— markdown ì¶”ê°€ + ì •ê·œí™”
    sections_normalized = []
    for s in sections_sorted:
        section_id = s.get("section_id", "")
        raw_json = s.get("raw_json") or {}
        markdown = extract_markdown_from_section(s)
        
        sections_normalized.append({
            "section_id": section_id,
            "id": section_id,  # í˜¸í™˜ì„±
            "title": get_section_title(section_id),
            "status": s.get("status", "pending"),
            "order": SECTION_ORDER.index(section_id) + 1 if section_id in SECTION_ORDER else 99,
            # ğŸ”¥ í•µì‹¬: markdown í•„ë“œ!
            "markdown": markdown,
            "content": markdown,  # í˜¸í™˜ì„±
            "body_markdown": markdown,  # í˜¸í™˜ì„±
            # raw_json ì „ì²´ (í”„ë¡ íŠ¸ì—ì„œ ìƒì„¸ ë°ì´í„° í•„ìš”ì‹œ)
            "raw_json": raw_json,
            # ì£¼ìš” í•„ë“œ ì§ì ‘ ë…¸ì¶œ (í”„ë¡ íŠ¸ í¸ì˜)
            "confidence": raw_json.get("confidence", "MEDIUM"),
            "diagnosis": raw_json.get("diagnosis"),
            "hypotheses": raw_json.get("hypotheses"),
            "strategy_options": raw_json.get("strategy_options"),
            "recommended_strategy": raw_json.get("recommended_strategy"),
            "kpis": raw_json.get("kpis"),
            "risks": raw_json.get("risks"),
            # Calendar
            "annual_theme": raw_json.get("annual_theme"),
            "monthly_plans": raw_json.get("monthly_plans"),
            "quarterly_milestones": raw_json.get("quarterly_milestones"),
            "peak_months": raw_json.get("peak_months"),
            "risk_months": raw_json.get("risk_months"),
            # Sprint
            "mission_statement": raw_json.get("mission_statement"),
            "phase_1_offer": raw_json.get("phase_1_offer"),
            "phase_2_funnel": raw_json.get("phase_2_funnel"),
            "phase_3_content": raw_json.get("phase_3_content"),
            "phase_4_automation": raw_json.get("phase_4_automation"),
            "milestones": raw_json.get("milestones"),
            "risk_scenarios": raw_json.get("risk_scenarios"),
            # ë©”íƒ€
            "char_count": len(markdown),
            "error": s.get("error"),
            "updated_at": s.get("updated_at"),
        })
    
    # 5) full_markdown ìƒì„± (í”„ë¡ íŠ¸ ë‹¨ìˆœ ë Œë”ìš©)
    full_markdown_parts = []
    for s in sections_normalized:
        if s.get("markdown"):
            full_markdown_parts.append(f"# {s['title']}\n\n{s['markdown']}")
    full_markdown = "\n\n---\n\n".join(full_markdown_parts)
    
    # 6) input_json (ì‚¬ì£¼ ë°ì´í„° - ì´ë©”ì¼ ë§í¬ì—ì„œë„ birth/time í‘œì‹œ)
    input_json = job.get("input_json") or {}
    
    # 7) ğŸ”¥ ì§‘ê³„ ì‘ë‹µ ë°˜í™˜
    return {
        "job": {
            "id": job["id"],
            "status": job.get("status"),
            "progress": job.get("progress", 0),
            "result_json": job.get("result_json"),
            "markdown": job.get("markdown"),
            "error": job.get("error"),
            "created_at": job.get("created_at"),
            "updated_at": job.get("updated_at"),
        },
        # ğŸ”¥ P0: input_json (ì‚¬ì£¼ ì›êµ­ ë°ì´í„° - localStorage ì˜ì¡´ ì œê±°)
        "input": input_json,
        # ğŸ”¥ P0 í•µì‹¬: sections ë°°ì—´ (7ê°œ, ì •ë ¬ë¨, markdown í¬í•¨)
        "sections": sections_normalized,
        # ğŸ”¥ P0: full_markdown (í•œ ë²ˆì— ë Œë” ê°€ëŠ¥)
        "full_markdown": full_markdown,
        # ë©”íƒ€
        "section_count": len(sections_normalized),
    }


@router.get("/verify/{job_id}")
async def verify_token(job_id: str, token: str = Query(..., description="Access token")):
    """job_id + token ê²€ì¦ API"""
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    if not token:
        raise HTTPException(status_code=400, detail="Token required")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    is_valid, job = await supabase.verify_job_token(job_id, token)
    
    if not is_valid:
        raise HTTPException(status_code=403, detail="Invalid token")
    
    return {
        "valid": True,
        "job_id": job["id"],
        "status": job.get("status"),
        "progress": job.get("progress", 0),
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”¥ ë™ì  ê²½ë¡œëŠ” ë§ˆì§€ë§‰ì—!
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@router.get("/{job_id}/status")
async def get_job_status(job_id: str):
    """í´ë§ìš© ìƒíƒœ ì¡°íšŒ"""
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        return {"job_id": job_id, "status": "unknown", "progress": 0}
    
    try:
        job = await supabase.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")
        
        sections_data = await supabase.get_sections(job_id)
        completed = len([s for s in sections_data if s.get("status") in ("completed", "done", "success")])
        progress = max(job.get("progress", 0), int((completed / 7) * 100))
        
        return {
            "job_id": job_id,
            "status": job.get("status", "unknown"),
            "progress": progress,
            "sections": [{"id": s.get("section_id"), "status": s.get("status")} for s in sections_data],
            "error": job.get("error"),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e)[:200])


@router.get("/{job_id}")
async def get_report_status(job_id: str, token: Optional[str] = Query(None)):
    """í´ë§ìš© ìƒíƒœ ì¡°íšŒ (í† í° ì˜µì…˜)"""
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id format: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        return {"job_id": job_id, "status": "unknown", "progress": 0}
    
    try:
        if token:
            is_valid, job = await supabase.verify_job_token(job_id, token)
            if not is_valid:
                raise HTTPException(status_code=403, detail="Invalid token")
        else:
            job = await supabase.get_job(job_id)
        
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")
        
        sections_data = await supabase.get_sections(job_id)
        
        return {
            "job_id": job_id,
            "status": job.get("status", "unknown"),
            "progress": job.get("progress", 0),
            "sections": [{"id": s.get("section_id"), "status": s.get("status")} for s in sections_data],
            "error": job.get("error"),
            "result": job.get("result_json") if job.get("status") == "completed" else None,
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e)[:200])


@router.get("/{job_id}/result")
async def get_report_result(job_id: str, token: Optional[str] = Query(None)):
    """
    ğŸ”¥ P0: /resultë„ job + sections ì§‘ê³„ ë°˜í™˜ (viewì™€ ë™ì¼ êµ¬ì¡°)
    """
    try:
        uuid.UUID(job_id)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid job_id: {job_id}")
    
    supabase = get_supabase()
    
    if not supabase or not supabase.is_available():
        raise HTTPException(status_code=503, detail="Supabase ë¯¸ì—°ê²°")
    
    if token:
        is_valid, job = await supabase.verify_job_token(job_id, token)
        if not is_valid:
            raise HTTPException(status_code=403, detail="Invalid token")
    else:
        job = await supabase.get_job(job_id)
    
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    
    if job.get("status") != "completed":
        return {"completed": False, "status": job.get("status"), "progress": job.get("progress", 0)}
    
    # ğŸ”¥ sections ì¡°íšŒ ë° ì •ê·œí™” (viewì™€ ë™ì¼)
    sections_raw = await supabase.get_sections(job_id)
    sections_sorted = sorted(
        sections_raw or [],
        key=lambda x: SECTION_ORDER.index(x.get("section_id", "")) if x.get("section_id") in SECTION_ORDER else 999
    )
    
    sections_normalized = []
    for s in sections_sorted:
        section_id = s.get("section_id", "")
        raw_json = s.get("raw_json") or {}
        markdown = extract_markdown_from_section(s)
        
        sections_normalized.append({
            "section_id": section_id,
            "id": section_id,
            "title": get_section_title(section_id),
            "markdown": markdown,
            "raw_json": raw_json,
            "status": s.get("status"),
        })
    
    full_markdown = "\n\n---\n\n".join([
        f"# {s['title']}\n\n{s['markdown']}" for s in sections_normalized if s.get("markdown")
    ])
    
    input_json = job.get("input_json") or {}
    
    return {
        "completed": True,
        "job": {
            "id": job["id"],
            "status": job.get("status"),
            "result_json": job.get("result_json"),
        },
        "input": input_json,
        "sections": sections_normalized,
        "full_markdown": full_markdown,
        "result": job.get("result_json"),
        "markdown": job.get("markdown") or full_markdown,
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

async def run_report_job(job_id: str, rulestore):
    """ë°±ê·¸ë¼ìš´ë“œ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        from app.services.report_worker import report_worker
        await report_worker.run_job(job_id, rulestore)
    except Exception as e:
        logger.error(f"Report job ì‹¤íŒ¨: {job_id} | {e}")
        supabase = get_supabase()
        if supabase:
            try:
                await supabase.fail_job(job_id, str(e))
            except:
                pass
